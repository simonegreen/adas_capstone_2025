{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c02a348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/homebrew/lib/python3.10/site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-24.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7652df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/lib/python3.10/site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/homebrew/lib/python3.10/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/s_gre1/Library/Python/3.10/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/s_gre1/Library/Python/3.10/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/s_gre1/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d895795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn-extra\n",
      "  Downloading scikit-learn-extra-0.3.0.tar.gz (818 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn-extra) (2.1.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn-extra) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn-extra) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.5.0)\n",
      "Building wheels for collected packages: scikit-learn-extra\n",
      "  Building wheel for scikit-learn-extra (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.3.0-cp310-cp310-macosx_12_0_arm64.whl size=417082 sha256=8ea3db9908f88e5cac7ff219f68a95e14d28d2f0332f91a087e5d3e5306eb3dc\n",
      "  Stored in directory: /Users/s_gre1/Library/Caches/pip/wheels/60/e1/7f/881b5af199acf453d55d49d38e227d291fe5b562099ac29a68\n",
      "Successfully built scikit-learn-extra\n",
      "Installing collected packages: scikit-learn-extra\n",
      "Successfully installed scikit-learn-extra-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f00d1a",
   "metadata": {},
   "source": [
    "### Helper Functions: Algorithms & Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5c78b",
   "metadata": {},
   "source": [
    "**Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8fe4e",
   "metadata": {},
   "source": [
    "TO DO: add a \"mode\" argument to each algorithm that, if mode = 1 the cluster labelling is output and if mode = 0 the silhouette coefficient is output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbfd14e3-20b2-4404-a2ea-ff8f7e5aa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for KMeans\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def kmeans_clustering(samples, mode, n_clusters=2, max_iter=300):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering on the input samples\n",
    "    \n",
    "    Parameters:\n",
    "        samples: array-like, shape (n_samples, n_features)\n",
    "        n_clusters: int, number of clusters (default=2)\n",
    "        max_iter: int, maximum iterations (default=300)\n",
    "    \n",
    "    Returns:\n",
    "        silhouette_coef: silhouette coefficient score\n",
    "    \"\"\"\n",
    "    k_means = KMeans(n_clusters=n_clusters, max_iter=max_iter)\n",
    "    k_means.fit(samples)\n",
    "\n",
    "    # Get cluster labels\n",
    "    labels = k_means.labels_\n",
    "\n",
    "    # If mode=1, return the cluster labels\n",
    "    if mode == 1:\n",
    "        return labels\n",
    "    \n",
    "    # Otherwise, calculate and return the silhouette score\n",
    "    try:\n",
    "        silhouette_coef = silhouette_score(samples, k_means.labels_, metric='euclidean')\n",
    "    except ValueError:\n",
    "        silhouette_coef = 0  # Assigning lowest score if clustering fails\n",
    "    return silhouette_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d63cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM Clustering Code\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def em_clustering(selected_features, mode, n_clusters=2):\n",
    "    \"\"\"\n",
    "    Perform EM Clustering on selected features and return silhouette score.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Silhouette score of the clustering (-1 if clustering fails)\n",
    "    \"\"\"\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize and fit the EM model\n",
    "    em_model = GaussianMixture(\n",
    "        n_components=n_clusters,\n",
    "        random_state=0, #THOUGHTS: We can improve this later to have an array of seeds to select from to observe variations\n",
    "        n_init=10  # Multiple initializations to avoid local optima\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Fit the model and get cluster assignments\n",
    "        em_model.fit(X_scaled)\n",
    "        labels = em_model.predict(X_scaled)\n",
    "\n",
    "        # If mode=1, return the cluster labels\n",
    "        if mode == 1:\n",
    "            return labels\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    except Exception as e:\n",
    "        #print(f\"Clustering failed: {str(e)}\")\n",
    "        silhouette_coef = 0  # Assigning lowest score if clustering fails\n",
    "    \n",
    "    return silhouette_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9944db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Detection method: \n",
    "# I put 'optimization part' in 'DBSCAN_Optimization_Code.ipynb' file. \n",
    "# We can use optimization after initial run to do a comparison and analysis in our paper to show improvements.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def dbscan_clustering(selected_features, mode, eps=0.5, min_samples=5):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on selected features\n",
    "    \n",
    "    Parameters:\n",
    "    selected_features : pandas DataFrame\n",
    "        The features selected for clustering\n",
    "    eps : float\n",
    "        The maximum distance between two samples for them to be considered neighbors\n",
    "    min_samples : int\n",
    "        The number of samples in a neighborhood for a point to be considered a core point\n",
    "        \n",
    "    Returns:\n",
    "    float : silhouette coefficient\n",
    "    dict : additional clustering information\n",
    "    \"\"\"\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize and fit DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X_scaled)\n",
    "    \n",
    "    # Get number of clusters (excluding noise points which are labeled -1, K Medoids does not have noise points)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "    # If mode=1, return the cluster labels\n",
    "    if mode == 1:\n",
    "        return labels\n",
    "    \n",
    "    # Calculate silhouette score if more than one cluster and no noise points\n",
    "    if n_clusters > 1 and -1 not in labels:\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    else:\n",
    "        silhouette_coef = 0  # Assign lowest score if clustering fails\n",
    "\n",
    "    \n",
    "    # NOTE: -- Uncomment when we analyze and optimize ---- Additional clustering information\n",
    "    # info = {\n",
    "    #     'n_clusters': n_clusters,\n",
    "    #     'n_noise': list(labels).count(-1),\n",
    "    #     'labels': labels,\n",
    "    #     'cluster_sizes': pd.Series(labels).value_counts().to_dict()\n",
    "    # }\n",
    "    \n",
    "    return silhouette_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16776843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K Medoids\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kmedoids_clustering(selected_features, mode, n_clusters=2, max_iter=1000):\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize and fit the K-Medoids model\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters, method='pam', max_iter=max_iter, random_state=0)\n",
    "    labels = kmedoids.fit_predict(X_scaled)\n",
    "\n",
    "    # If mode=1, return the cluster labels\n",
    "    if mode == 1:\n",
    "        return labels\n",
    "\n",
    "    # Otherwise, calculate and return the silhouette score\n",
    "    try:\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    except ValueError:\n",
    "        silhouette_coef = 0  # Assigning lowest score if clustering fails\n",
    "\n",
    "    return silhouette_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078cfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes for Mean Shift\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def meanshift_clustering(selected_features, mode, bandwidth=None):\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize and fit the Mean Shift model\n",
    "    meanshift = MeanShift(bandwidth=bandwidth)\n",
    "    labels = meanshift.fit_predict(X_scaled)\n",
    "\n",
    "    # Check and print the number of clusters determined \n",
    "    n_clusters = len(np.unique(labels))\n",
    "    print(f\"Number of clusters found: {n_clusters}\")\n",
    "\n",
    "    # If mode=1, return the cluster labels\n",
    "    if mode == 1:\n",
    "        return labels\n",
    "\n",
    "    # Otherwise, calculate and return the silhouette score\n",
    "    try:\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    except ValueError:\n",
    "        silhouette_coef = 0  # Assign lowest score if clustering fails\n",
    "    \n",
    "    return silhouette_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946bd80",
   "metadata": {},
   "source": [
    "**Clustering & Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Takes in the state (feature configuration) and action (algorithm) that\n",
    "produced the max value in the Q-Matrix to produce the final cluster'''\n",
    "def get_cluster(state, action):\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740d094",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7245129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FEATURES = {0: 'avg_bytes_sent', 1: 'avg_bytes_received', 2: 'avg_packets_transferred', \n",
    "  3: 'avg_flow_duration', 4: 'recent_tcp_flags', 5: 'recent_protocol', 6: 'avg_cpu_usage', \n",
    "  7: 'avg_memory_usage', 8: 'avg_disk_usage', 9: 'avg_uptime'}\n",
    "\n",
    "data = pd.read_csv(\"joined_quantitative_data.csv\")\n",
    "\n",
    "ALGORITHMS = {0: 'K-Means', 1: 'Mean Shift', 2: 'K-Mediods', 3: 'EM Clustering', 4: 'DBSCAN Clustering'}\n",
    "NUM_ALG = len(ALGORITHMS)\n",
    "original_features = data.iloc[:, 2:]\n",
    "ips = data['source_ip']\n",
    "#print(original_features.columns)\n",
    "#print(ips.head(10))\n",
    "\n",
    "def algorithm_prep(state, action, mode):\n",
    "  # convert state to binary\n",
    "  state_bin = bin(state)\n",
    "  #print(state_bin)\n",
    "  state_bin_arr = np.array([b for b in state_bin[2:]])\n",
    "  # pad with zeros\n",
    "  diff = 10 - len(state_bin_arr)\n",
    "  padded_arr = np.insert(state_bin_arr, 0, ['0' for i in range(diff)])\n",
    "  #(padded_arr)\n",
    "  # identify which indexes are 1\n",
    "  idx = (np.where(padded_arr == '1')[0]).tolist()\n",
    "  #print(idx)\n",
    "  # select feature headings\n",
    "  selected_features = original_features.iloc[:,idx]\n",
    "  #print(selected_features.head(10))\n",
    "  # select algorithm\n",
    "  # algo = action\n",
    "  # prep correct data - done\n",
    "  \n",
    "  # call algorithm function\n",
    "  out = None\n",
    "  #print('algorithm:',ALGORITHMS[action])\n",
    "\n",
    "  # if mode = 0, output is the silhouette coefficient\n",
    "  # if mode = 1, output is the cluster labelling\n",
    "  match action:\n",
    "    case 0:\n",
    "      #print('algorithm:',ALGORITHMS[action])\n",
    "      out = kmeans_clustering(selected_features, mode)\n",
    "    case 1: \n",
    "      #print('algorithm:',ALGORITHMS[action])\n",
    "      out = meanshift_clustering(selected_features, mode)\n",
    "    case 2:\n",
    "      #print('algorithm:',ALGORITHMS[action])\n",
    "      out = kmedoids_clustering(selected_features, mode)\n",
    "    case 3: \n",
    "      out = em_clustering(selected_features, mode)\n",
    "    case 4:\n",
    "      out = dbscan_clustering(selected_features, mode)\n",
    "  # return silhouette from algorithm function\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e31d04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6307170631786834)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_prep(1, 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9beedbfe-7d34-401e-b99f-e48e93937a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering failed: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering failed: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering failed: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q  :\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [ 1.12714607  0.52921146  0.63071706  0.63071706 -1.        ]\n",
      " [ 0.55761235 -1.8         0.55761235  0.55929848 -1.        ]\n",
      " ...\n",
      " [ 1.4163     -0.74825001  0.13145184  0.79819204 -1.8       ]\n",
      " [ 1.7712977  -0.10722941  0.1199422   0.7984389  -1.        ]\n",
      " [ 1.87192697  0.665209    0.396487    0.78066054 -1.        ]]\n",
      "Normed Q :\n",
      "[[  0.           0.           0.           0.           0.        ]\n",
      " [ 59.46257281  27.91854209  33.27346864  33.27346864 -52.75498411]\n",
      " [ 29.41683065 -94.95897139  29.41683065  29.50578268 -52.75498411]\n",
      " ...\n",
      " [ 74.71688411 -39.47391749   6.93473992  42.10860817 -94.95897139]\n",
      " [ 93.44478178  -5.65688581   6.32754911  42.12163172 -52.75498411]\n",
      " [ 98.75347744  35.09309018  20.91666532  41.18373425 -52.75498411]]\n"
     ]
    }
   ],
   "source": [
    "# Markov Decision Process (MDP) - The Bellman equations adapted to\n",
    "# Q Learning.Reinforcement Learning with the Q action-value(reward) function.\n",
    "# Copyright 2018 Denis Rothman MIT License. See LICENSE.\n",
    "import numpy as ql\n",
    "# R is The Reward Matrix for each state\n",
    "# 1024 configurations of the 10 features --> 2^10\n",
    "# 5 algorithms\n",
    "R = ql.matrix(ql.zeros([1024,5]))\n",
    "\n",
    "# Q is the Learning Matrix in which rewards will be learned/stored\n",
    "Q = ql.matrix(ql.zeros([1024,5]))\n",
    "\n",
    "# Gamma : It's a form of penalty or uncertainty for learning\n",
    "# If the value is 1 , the rewards would be too high.\n",
    "# This way the system knows it is learning.\n",
    "gamma = 0.8\n",
    "\n",
    "# agent_s_state. The agent the name of the system calculating\n",
    "# s is the state the agent is going from and s' the state it's going to\n",
    "# this state can be random or it can be chosen as long as the rest of the choices\n",
    "# are not determined. Randomness is part of this stochastic process\n",
    "# 1) TO-DO: decide if starting state is random or a specific state\n",
    "agent_s_state = 1\n",
    "\n",
    "# The possible \"a\" actions when the agent is in a given state\n",
    "def possible_actions(state):\n",
    "    # 2) DONE: we should check Q, not R because R is never modified\n",
    "    current_state_row = Q[state,]\n",
    "    # 3) DONE: this should pick valid actions based on what we have not visited\n",
    "    possible_act = ql.where(current_state_row == 0)[1]\n",
    "    return possible_act\n",
    "\n",
    "# Get available actions in the current state\n",
    "PossibleAction = possible_actions(agent_s_state)\n",
    "\n",
    "# This function chooses at random which action to be performed within the range \n",
    "# of all the available actions.\n",
    "def ActionChoice(available_actions_range):\n",
    "    if(sum(PossibleAction)>0):\n",
    "        next_action = int(ql.random.choice(PossibleAction,1)[0])\n",
    "    if(sum(PossibleAction)<=0):\n",
    "        next_action = int(np.random.choice(NUM_ALG+1,1)[0])\n",
    "    return next_action\n",
    "\n",
    "# Sample next action to be performed\n",
    "action = ActionChoice(PossibleAction)\n",
    "\n",
    "# A version of Bellman's equation for reinforcement learning using the Q function\n",
    "# This reinforcement algorithm is a memoryless process\n",
    "# The transition function T from one state to another\n",
    "# is not in the equation below.  T is done by the random choice above\n",
    "\n",
    "def reward(current_state, action, gamma):\n",
    "    Max_State = ql.where(Q[action,] == ql.max(Q[action,]))[1]\n",
    "\n",
    "    if Max_State.shape[0] > 1:\n",
    "        Max_State = int(ql.random.choice(Max_State, size = 1)[0])\n",
    "    else:\n",
    "        Max_State = int(Max_State[0])\n",
    "\n",
    "    # 5) DONE: we think this is a typo and action/Max_State should be switched. \n",
    "    # MaxValue = Q[action, Max_State]\n",
    "    MaxValue = Q[Max_State, action]\n",
    "\n",
    "    # 6) DONE: call function to run ML algorithm using the value of action. this will\n",
    "    # run the algorithm using the features from current_state, create clusters,\n",
    "    # and calculate the silhouette value.\n",
    "    silhouette_co = algorithm_prep(current_state, action, 0) \n",
    "    \n",
    "    # Bellman's MDP based Q function\n",
    "    # 7) DONE: instead of getting a value from R, we add the silhouette value to gamma * MaxValue\n",
    "    # Q[current_state, action] = R[current_state, action] + gamma * MaxValue\n",
    "    Q[current_state, action] = silhouette_co + gamma * MaxValue\n",
    "\n",
    "\n",
    "# Rewarding Q matrix\n",
    "reward(agent_s_state,action,gamma)\n",
    "\n",
    "\n",
    "# Leraning over n iterations depending on the convergence of the system\n",
    "# A convergence function can replace the systematic repeating of the process\n",
    "# by comparing the sum of the Q matrix to that of Q matrix n-1 in the\n",
    "# previous episode\n",
    "for i in range(6000):\n",
    "    # select a random new state (configuration of features)\n",
    "    current_state = ql.random.randint(1, int(Q.shape[0]))\n",
    "    PossibleAction = possible_actions(current_state)\n",
    "    action = ActionChoice(PossibleAction)\n",
    "    reward(current_state,action,gamma)\n",
    "    \n",
    "# Displaying Q before the norm of Q phase\n",
    "print(\"Q  :\")\n",
    "print(Q)\n",
    "\n",
    "# Norm of Q\n",
    "print(\"Normed Q :\")\n",
    "print(Q/ql.max(Q)*100)\n",
    "\n",
    "# DONE: get maximum value from Q-Learning Matrix\n",
    "normed_Q = Q/ql.max(Q)*100\n",
    "max_location = np.where(normed_Q==normed_Q.max())\n",
    "print(\"max value located at\",max_location)\n",
    "max_config = max_location[0][0]\n",
    "max_algorithm = ALGORITHMS[max_location[1][0]]\n",
    "print(f\"Using algorithm {max_algorithm} and feature configuration {max_config}, max value is:\",normed_Q[278,0])\n",
    "\n",
    "# TO-DO: get final cluster labels\n",
    "cluster_labels = get_cluster(max_config, max_algorithm)\n",
    "\n",
    "# TO-DO: match data in clusters to IP addresses\n",
    "\n",
    "\n",
    "# TO-DO: return what IPs are likely anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66c348f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value located at (array([278]), array([0]))\n",
      "278\n",
      "Using algorithm K-Means and feature configuration 278, max value is: 100.0\n"
     ]
    }
   ],
   "source": [
    "normed_Q = Q/ql.max(Q)*100\n",
    "max_location = np.where(normed_Q==normed_Q.max())\n",
    "print(\"max value located at\",max_location)\n",
    "max_config = max_location[0][0]\n",
    "max_algorithm = ALGORITHMS[max_location[1][0]]\n",
    "print(f\"Using algorithm {max_algorithm} and feature configuration {max_config}, max value is:\",normed_Q[278,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa379bf0",
   "metadata": {},
   "source": [
    "## Additional Reference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b7bb23-50fc-4abd-8090-852424c7c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q  :\n",
      "[[  0.      0.      0.      0.    258.44    0.   ]\n",
      " [  0.      0.      0.    321.8     0.    207.752]\n",
      " [  0.      0.    500.    321.8     0.      0.   ]\n",
      " [  0.    258.44  401.      0.    258.44    0.   ]\n",
      " [207.752   0.      0.    321.8     0.      0.   ]\n",
      " [  0.    258.44    0.      0.      0.      0.   ]]\n",
      "Normed Q :\n",
      "[[  0.       0.       0.       0.      51.688    0.    ]\n",
      " [  0.       0.       0.      64.36     0.      41.5504]\n",
      " [  0.       0.     100.      64.36     0.       0.    ]\n",
      " [  0.      51.688   80.2      0.      51.688    0.    ]\n",
      " [ 41.5504   0.       0.      64.36     0.       0.    ]\n",
      " [  0.      51.688    0.       0.       0.       0.    ]]\n",
      "Concept Path\n",
      "-> A\n",
      "-> E\n",
      "-> D\n",
      "-> C\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Markov Decision Process (MDP) - The Bellman equations adapted to\n",
    "# Q Learning.Reinforcement Learning with the Q action-value(reward) function.\n",
    "# Copyright 2019 Denis Rothman MIT License. See LICENSE.\n",
    "import numpy as ql\n",
    "# R is The Reward Matrix for each state\n",
    "R = ql.matrix([ [0,0,0,0,1,0],\n",
    "\t\t            [0,0,0,1,0,1],\n",
    "\t\t            [0,0,100,1,0,0],\n",
    "\t             \t[0,1,1,0,1,0],\n",
    "\t\t            [1,0,0,1,0,0],\n",
    "\t\t            [0,1,0,0,0,0] ])\n",
    "\n",
    "# Q is the Learning Matrix in which rewards will be learned/stored\n",
    "Q = ql.matrix(ql.zeros([6,6]))\n",
    "\n",
    "\"\"\"##  The Learning rate or training penalty\"\"\"\n",
    "\n",
    "# Gamma : It's a form of penalty or uncertainty for learning\n",
    "# If the value is 1 , the rewards would be too high.\n",
    "# This way the system knows it is learning.\n",
    "gamma = 0.8\n",
    "\n",
    "\"\"\"## Initial State\"\"\"\n",
    "\n",
    "# agent_s_state. The agent the name of the system calculating\n",
    "# s is the state the agent is going from and s' the state it's going to\n",
    "# this state can be random or it can be chosen as long as the rest of the choices\n",
    "# are not determined. Randomness is part of this stochastic process\n",
    "agent_s_state = 5\n",
    "\n",
    "\"\"\"## The random choice of the next state\"\"\"\n",
    "\n",
    "# The possible \"a\" actions when the agent is in a given state\n",
    "def possible_actions(state):\n",
    "    current_state_row = R[state,]\n",
    "    possible_act = ql.where(current_state_row >0)[1]\n",
    "    return possible_act\n",
    "\n",
    "# Get available actions in the current state\n",
    "PossibleAction = possible_actions(agent_s_state)\n",
    "\n",
    "# This function chooses at random which action to be performed within the range \n",
    "# of all the available actions.\n",
    "def ActionChoice(available_actions_range):\n",
    "    if(sum(PossibleAction)>0):\n",
    "        next_action = int(ql.random.choice(PossibleAction,1))\n",
    "    if(sum(PossibleAction)<=0):\n",
    "        next_action = int(ql.random.choice(5,1))\n",
    "    return next_action\n",
    "\n",
    "# Sample next action to be performed\n",
    "action = ActionChoice(PossibleAction)\n",
    "\n",
    "\"\"\"## The Bellman Equation\"\"\"\n",
    "\n",
    "# A version of the Bellman equation for reinforcement learning using the Q function\n",
    "# This reinforcement algorithm is a memoryless process\n",
    "# The transition function T from one state to another\n",
    "# is not in the equation below.  T is done by the random choice above\n",
    "\n",
    "def reward(current_state, action, gamma):\n",
    "    Max_State = ql.where(Q[action,] == ql.max(Q[action,]))[1]\n",
    "\n",
    "    if Max_State.shape[0] > 1:\n",
    "        Max_State = int(ql.random.choice(Max_State, size = 1))\n",
    "    else:\n",
    "        Max_State = int(Max_State)\n",
    "    MaxValue = Q[action, Max_State]\n",
    "    \n",
    "    # The Bellman MDP based Q function\n",
    "    Q[current_state, action] = R[current_state, action] + gamma * MaxValue\n",
    "\n",
    "# Rewarding Q matrix\n",
    "reward(agent_s_state,action,gamma)\n",
    "\n",
    "\"\"\"## Running the training episodes randomly\"\"\"\n",
    "\n",
    "# Learning over n iterations depending on the convergence of the system\n",
    "# A convergence function can replace the systematic repeating of the process\n",
    "# by comparing the sum of the Q matrix to that of Q matrix n-1 in the\n",
    "# previous episode\n",
    "for i in range(50000):\n",
    "    current_state = ql.random.randint(0, int(Q.shape[0]))\n",
    "    PossibleAction = possible_actions(current_state)\n",
    "    action = ActionChoice(PossibleAction)\n",
    "    reward(current_state,action,gamma)\n",
    "    \n",
    "# Displaying Q before the norm of Q phase\n",
    "print(\"Q  :\")\n",
    "print(Q)\n",
    "\n",
    "# Norm of Q\n",
    "print(\"Normed Q :\")\n",
    "print(Q/ql.max(Q)*100)\n",
    "\n",
    "\"\"\"# Improving the program by introducing a decision-making process\"\"\"\n",
    "nextc=-1\n",
    "nextci=-1\n",
    "conceptcode=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "origin=int(input(\"index number origin(A=0,B=1,C=2,D=3,E=4,F=5): \"))\n",
    "print(\"Concept Path\")\n",
    "print(\"->\",conceptcode[int(origin)])\n",
    "for se in range(0,6):\n",
    "    if(se==0):\n",
    "        po=origin\n",
    "    if(se>0):\n",
    "        po=nextci\n",
    "        #print(\"se:\",se,\"po:\",po)\n",
    "    for ci in range(0,6):\n",
    "        maxc=Q[po,ci]\n",
    "        #print(maxc,nextc)\n",
    "        if(maxc>=nextc):\n",
    "            nextc=maxc\n",
    "            nextci=ci\n",
    "            #print(\"next c\",nextc)\n",
    "    if(nextci==po):\n",
    "        break;\n",
    "    #print(\"present origin\",po,\"next c\",nextci,\" \",nextc,\" \",conceptcode[int(nextci)])\n",
    "    print(\"->\",conceptcode[int(nextci)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
