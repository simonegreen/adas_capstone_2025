{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c02a348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\aaaimeeeelll\\appdata\\roaming\\python\\python312\\site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7652df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (1.22.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d895795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn-extra in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn-extra) (1.22.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn-extra) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn-extra) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aaaimeeeelll\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f00d1a",
   "metadata": {},
   "source": [
    "### Helper Functions: Algorithms & Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5c78b",
   "metadata": {},
   "source": [
    "**Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8fe4e",
   "metadata": {},
   "source": [
    "DONE: add a \"mode\" argument to each algorithm that, if mode = 1 the cluster labelling is output and if mode = 0 the silhouette coefficient is output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbfd14e3-20b2-4404-a2ea-ff8f7e5aa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for KMeans\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def kmeans_clustering(samples,mode,  n_clusters=2, max_iter=300):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering on the input samples\n",
    "    \n",
    "    Parameters:\n",
    "        samples: array-like, shape (n_samples, n_features)\n",
    "        n_clusters: int, number of clusters (default=2)\n",
    "        max_iter: int, maximum iterations (default=300)\n",
    "    \n",
    "    Returns:\n",
    "        silhouette_coef: silhouette coefficient score\n",
    "    \"\"\"\n",
    "    k_means = KMeans(n_clusters=n_clusters, max_iter=max_iter)\n",
    "    k_means.fit(samples)\n",
    "    if mode == 0:\n",
    "        try:\n",
    "            silhouette_coef = silhouette_score(samples, k_means.labels_, metric='euclidean')\n",
    "        except ValueError:\n",
    "            silhouette_coef = 0  # Assigning lowest score if clustering fails\n",
    "        return silhouette_coef\n",
    "    if mode == 1:\n",
    "        return k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d63cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM Clustering Code\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def em_clustering(selected_features, mode, n_clusters=2):\n",
    "    \"\"\"\n",
    "    Perform EM Clustering on selected features and return silhouette score.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Silhouette score of the clustering (-1 if clustering fails)\n",
    "    \"\"\"\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize and fit the EM model\n",
    "    em_model = GaussianMixture(\n",
    "        n_components=n_clusters,\n",
    "        random_state=0, #THOUGHTS: We can improve this later to have an array of seeds to select from to observe variations\n",
    "        n_init=10  # Multiple initializations to avoid local optima\n",
    "    )\n",
    "    \n",
    "   \n",
    "    try:\n",
    "        # Fit the model and get cluster assignments\n",
    "        em_model.fit(X_scaled)\n",
    "        labels = em_model.predict(X_scaled)\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    except Exception as e:\n",
    "        #print(f\"Clustering failed: {str(e)}\")\n",
    "        silhouette_coef = 0  # Assigning lowest score if clustering fails\n",
    "    if mode == 0:\n",
    "        return silhouette_coef\n",
    "    if mode == 1:\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9944db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Detection method: \n",
    "# I put 'optimization part' in 'DBSCAN_Optimization_Code.ipynb' file. \n",
    "# We can use optimization after initial run to do a comparison and analysis in our paper to show improvements.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TO-DO: keep -1 --> they will be its own cluster\n",
    "def dbscan_clustering(selected_features, mode, eps=0.5, min_samples=5):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on selected features\n",
    "    \n",
    "    Parameters:\n",
    "    selected_features : pandas DataFrame\n",
    "        The features selected for clustering\n",
    "    eps : float\n",
    "        The maximum distance between two samples for them to be considered neighbors\n",
    "    min_samples : int\n",
    "        The number of samples in a neighborhood for a point to be considered a core point\n",
    "        \n",
    "    Returns:\n",
    "    float : silhouette coefficient\n",
    "    dict : additional clustering information\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize and fit DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X_scaled)\n",
    "    \n",
    "    # Get number of clusters (excluding noise points which are labeled -1, K Medoids does not have noise points)\n",
    "    n_clusters = len(set(labels))\n",
    "    \n",
    "    # calculate silhouette score if more than one cluster and  noise points\n",
    "    if n_clusters > 1:\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    else:\n",
    "        silhouette_coef = 0  # Assign lowest score if clustering fails\n",
    "\n",
    "    \n",
    "    # NOTE: -- Uncomment when we analyze and optimize ---- Additional clustering information\n",
    "    # info = {\n",
    "    #     'n_clusters': n_clusters,\n",
    "    #     'n_noise': list(labels).count(-1),\n",
    "    #     'labels': labels,\n",
    "    #     'cluster_sizes': pd.Series(labels).value_counts().to_dict()\n",
    "    # }\n",
    "    \n",
    "    if mode == 0:\n",
    "        return silhouette_coef\n",
    "    if mode == 1:\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16776843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K Medoids\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kmedoids_clustering(selected_features, mode, n_clusters=2):\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "     # Initialize and fit the K-Medoids model\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters, method='pam', max_iter=1000, random_state=0)\n",
    "    labels = kmedoids.fit_predict(X_scaled)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    try:\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    except ValueError:\n",
    "        silhouette_coef = 0  # Assigning lowest score if clustering fails\n",
    "    if mode == 0:\n",
    "        return silhouette_coef\n",
    "    if mode == 1:\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078cfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes for Mean Shift\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def meanshift_clustering(selected_features, mode, bandwidth=None):\n",
    "    # Filter the selected features\n",
    "    X = selected_features\n",
    "    \n",
    "    # Standardize selected features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize and fit the Mean Shift model\n",
    "    meanshift = MeanShift(bandwidth=bandwidth)\n",
    "    labels = meanshift.fit_predict(X_scaled)\n",
    "\n",
    "    # Check the number of clusters determined \n",
    "    n_clusters = len(np.unique(labels))\n",
    "    #print(f\"Number of clusters found: {n_clusters}\")\n",
    "    \n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    try:\n",
    "        silhouette_coef = silhouette_score(X_scaled, labels)\n",
    "    except ValueError:\n",
    "        silhouette_coef = 0  # Assign lowest score if clustering fails\n",
    "    if mode == 0:\n",
    "        return silhouette_coef\n",
    "    if mode == 1:\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946bd80",
   "metadata": {},
   "source": [
    "**Clustering & Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acda8c92",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (706375010.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [8]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "''' Takes in the state (feature configuration) and action (algorithm) that\n",
    "produced the max value in the Q-Matrix to produce the final cluster'''\n",
    "def get_cluster(state, action):\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740d094",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7245129f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m FEATURES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_bytes_sent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_bytes_received\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_packets_transferred\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m   \u001b[38;5;241m3\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_flow_duration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecent_tcp_flags\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecent_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m6\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_cpu_usage\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      6\u001b[0m   \u001b[38;5;241m7\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_memory_usage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m8\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_disk_usage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m9\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_uptime\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FEATURES = {0: 'avg_bytes_sent', 1: 'avg_bytes_received', 2: 'avg_packets_transferred', \n",
    "  3: 'avg_flow_duration', 4: 'recent_tcp_flags', 5: 'recent_protocol', 6: 'avg_cpu_usage', \n",
    "  7: 'avg_memory_usage', 8: 'avg_disk_usage', 9: 'avg_uptime'}\n",
    "\n",
    "data = pd.read_csv(\"joined_quantitative_data.csv\")\n",
    "\n",
    "ALGORITHMS = {0: 'K-Means', 1: 'Mean Shift', 2: 'K-Mediods', 3: 'EM Clustering', 4: 'DBSCAN Clustering'}\n",
    "NUM_ALG = len(ALGORITHMS)\n",
    "original_features = data.iloc[:, 2:]\n",
    "ips = data['source_ip']\n",
    "#print(original_features.columns)\n",
    "#print(ips.head(10))\n",
    "\n",
    "def algorithm_prep(state, action, mode):\n",
    "  # convert state to binary\n",
    "  state_bin = bin(state)\n",
    "  #print(state_bin)\n",
    "  state_bin_arr = np.array([b for b in state_bin[2:]])\n",
    "  # pad with zeros\n",
    "  diff = 10 - len(state_bin_arr)\n",
    "  padded_arr = np.insert(state_bin_arr, 0, ['0' for i in range(diff)])\n",
    "  #(padded_arr)\n",
    "  # identify which indexes are 1\n",
    "  idx = (np.where(padded_arr == '1')[0]).tolist()\n",
    "  #print(idx)\n",
    "  # select feature headings\n",
    "  selected_features = original_features.iloc[:,idx]\n",
    "  #print(selected_features.head(10))\n",
    "  # select algorithm\n",
    "  # algo = action\n",
    "  # prep correct data - done\n",
    "  \n",
    "  # call algorithm function\n",
    "  out = None\n",
    "  #print('algorithm:',ALGORITHMS[action])\n",
    "\n",
    "  # if mode = 0, output is the silhouette coefficient\n",
    "  # if mode = 1, output is the cluster labelling\n",
    "  match action:   \n",
    "    case 0:\n",
    "      #print('algorithm:',ALGORITHMS[action])\n",
    "      out = kmeans_clustering(selected_features, mode)\n",
    "    case 1: \n",
    "      #print('algorithm:',ALGORITHMS[action])\n",
    "      out = meanshift_clustering(selected_features, mode)\n",
    "    case 2:\n",
    "      #print('algorithm:',ALGORITHMS[action])\n",
    "      out = kmedoids_clustering(selected_features, mode)\n",
    "    case 3: \n",
    "      out = em_clustering(selected_features, mode)\n",
    "    case 4:\n",
    "      out = dbscan_clustering(selected_features, mode)\n",
    "  # return silhouette from algorithm function\n",
    "  return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148db5c",
   "metadata": {},
   "source": [
    "##### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e31d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "[1]\n",
      "IP 192.168.0.248 is a potential anomaly\n",
      "IP 192.168.0.78 is a potential anomaly\n"
     ]
    }
   ],
   "source": [
    "label_test = algorithm_prep(256, 0,1)\n",
    "labelled_data = data.copy()\n",
    "labelled_data['cluster'] = label_test\n",
    "labelled_data.head(10)\n",
    "\n",
    "num_clusters = labelled_data['cluster'].nunique()\n",
    "vals = labelled_data['cluster'].value_counts().values\n",
    "print(labelled_data.shape[0])\n",
    "vals = vals / labelled_data.shape[0]\n",
    "idx = (np.where(vals <= 0.1)[0]).tolist()\n",
    "print(idx)\n",
    "anomalies = labelled_data.loc[labelled_data['cluster'].isin(idx)]\n",
    "#print(anomalies)\n",
    "for i in anomalies['source_ip']:\n",
    "    print(f\"IP {i} is a potential anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beedbfe-7d34-401e-b99f-e48e93937a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn_extra/cluster/_k_medoids.py:297: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q  :\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.63040802 0.52921146 0.91619417 0.63071706 0.        ]\n",
      " [0.         0.         0.84308946 0.55929848 0.        ]\n",
      " ...\n",
      " [0.97021012 0.69174999 0.80592341 0.79819204 0.        ]\n",
      " [0.97021139 0.         0.40541931 0.7984389  0.        ]\n",
      " [0.97021012 0.665209   0.         0.78066054 0.        ]]\n",
      "Normed Q :\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [34.34635478 28.83288904 49.91676662 34.36319226  0.        ]\n",
      " [ 0.          0.         45.93382171 30.4721126   0.        ]\n",
      " ...\n",
      " [52.85970352 37.68843309 43.90891367 43.48768726  0.        ]\n",
      " [52.85977285  0.         22.08835404 43.50113733  0.        ]\n",
      " [52.85970312 36.24240736  0.         42.53252323  0.        ]]\n",
      "\n",
      "max value located at (array([306]), array([0]))\n",
      "\n",
      "Using algorithm K-Means and feature configuration 306, max value is: 100.0\n",
      "\n",
      "IP 192.168.0.248 is a potential anomaly\n",
      "\n",
      "IP 192.168.0.78 is a potential anomaly\n"
     ]
    }
   ],
   "source": [
    "# Markov Decision Process (MDP) - The Bellman equations adapted to\n",
    "# Q Learning.Reinforcement Learning with the Q action-value(reward) function.\n",
    "# Copyright 2018 Denis Rothman MIT License. See LICENSE.\n",
    "import numpy as ql\n",
    "# R is The Reward Matrix for each state\n",
    "# 1024 configurations of the 10 features --> 2^10\n",
    "# 5 algorithms\n",
    "R = ql.matrix(ql.zeros([1024,5]))\n",
    "\n",
    "# Q is the Learning Matrix in which rewards will be learned/stored\n",
    "Q = ql.matrix(ql.zeros([1024,5]))\n",
    "\n",
    "# Gamma : It's a form of penalty or uncertainty for learning\n",
    "# If the value is 1 , the rewards would be too high.\n",
    "# This way the system knows it is learning.\n",
    "gamma = 0.8\n",
    "\n",
    "# agent_s_state. The agent the name of the system calculating\n",
    "# s is the state the agent is going from and s' the state it's going to\n",
    "# this state can be random or it can be chosen as long as the rest of the choices\n",
    "# are not determined. Randomness is part of this stochastic process\n",
    "# 1) DONE: decide if starting state is random or a specific state\n",
    "agent_s_state = 1\n",
    "\n",
    "# The possible \"a\" actions when the agent is in a given state\n",
    "def possible_actions(state):\n",
    "    # 2) DONE: we should check Q, not R because R is never modified\n",
    "    current_state_row = Q[state,]\n",
    "    # 3) DONE: this should pick valid actions based on what we have not visited\n",
    "    possible_act = ql.where(current_state_row == 0)[1]\n",
    "    return possible_act\n",
    "\n",
    "# Get available actions in the current state\n",
    "PossibleAction = possible_actions(agent_s_state)\n",
    "\n",
    "# This function chooses at random which action to be performed within the range \n",
    "# of all the available actions.\n",
    "def ActionChoice(available_actions_range):\n",
    "    if(sum(PossibleAction)>0):\n",
    "        next_action = int(ql.random.choice(PossibleAction,1)[0])\n",
    "    if(sum(PossibleAction)<=0):\n",
    "        next_action = int(np.random.choice(NUM_ALG+1,1)[0])\n",
    "    return next_action\n",
    "\n",
    "# Sample next action to be performed\n",
    "action = ActionChoice(PossibleAction)\n",
    "\n",
    "# A version of Bellman's equation for reinforcement learning using the Q function\n",
    "# This reinforcement algorithm is a memoryless process\n",
    "# The transition function T from one state to another\n",
    "# is not in the equation below.  T is done by the random choice above\n",
    "\n",
    "def reward(current_state, action, gamma):\n",
    "    Max_State = ql.where(Q[action,] == ql.max(Q[action,]))[1]\n",
    "\n",
    "    if Max_State.shape[0] > 1:\n",
    "        Max_State = int(ql.random.choice(Max_State, size = 1)[0])\n",
    "    else:\n",
    "        Max_State = int(Max_State[0])\n",
    "\n",
    "    # 5) DONE: we think this is a typo and action/Max_State should be switched. \n",
    "    # MaxValue = Q[action, Max_State]\n",
    "    MaxValue = Q[Max_State, action]\n",
    "\n",
    "    # 6) DONE: call function to run ML algorithm using the value of action. this will\n",
    "    # run the algorithm using the features from current_state, create clusters,\n",
    "    # and calculate the silhouette value.\n",
    "    silhouette_co = algorithm_prep(current_state, action, 0) \n",
    "    \n",
    "    # Bellman's MDP based Q function\n",
    "    # 7) DONE: instead of getting a value from R, we add the silhouette value to gamma * MaxValue\n",
    "    # Q[current_state, action] = R[current_state, action] + gamma * MaxValue\n",
    "    Q[current_state, action] = silhouette_co + gamma * MaxValue\n",
    "\n",
    "\n",
    "# Rewarding Q matrix\n",
    "reward(agent_s_state,action,gamma)\n",
    "\n",
    "\n",
    "# Leraning over n iterations depending on the convergence of the system\n",
    "# A convergence function can replace the systematic repeating of the process\n",
    "# by comparing the sum of the Q matrix to that of Q matrix n-1 in the\n",
    "# previous episode\n",
    "for i in range(6000):\n",
    "    # select a random new state (configuration of features)\n",
    "    current_state = ql.random.randint(1, int(Q.shape[0]))\n",
    "    PossibleAction = possible_actions(current_state)\n",
    "    action = ActionChoice(PossibleAction)\n",
    "    reward(current_state,action,gamma)\n",
    "    \n",
    "# Displaying Q before the norm of Q phase\n",
    "print(\"Q  :\")\n",
    "print(Q)\n",
    "\n",
    "# Norm of Q\n",
    "print(\"Normed Q :\")\n",
    "print(Q/ql.max(Q)*100)\n",
    "\n",
    "# DONE: get maximum value from Q-Learning Matrix\n",
    "normed_Q = Q/ql.max(Q)*100\n",
    "max_location = np.where(normed_Q==normed_Q.max())\n",
    "print(\"\\nmax value located at\",max_location)\n",
    "max_config = max_location[0][0]\n",
    "max_algorithm = max_location[1][0]\n",
    "print(f\"\\nUsing algorithm {ALGORITHMS[max_algorithm]} and feature configuration {max_config}, max value is:\",normed_Q[max_config,max_algorithm])\n",
    "#TO-DO: print(f\"Selected features:\", )\n",
    "\n",
    "# DONE: get final cluster labels\n",
    "cluster_labels = algorithm_prep(max_config, max_algorithm, 1)\n",
    "\n",
    "# DONE: match data in clusters to IP addresses\n",
    "labelled_data = data.copy()\n",
    "labelled_data['cluster'] = cluster_labels\n",
    "\n",
    "# TO-DO: return what IPs are likely anomalous\n",
    "# see what clusters have < 5% of the data\n",
    "# get unique values in cluster column\n",
    "num_clusters = labelled_data['cluster'].nunique()\n",
    "\n",
    "# for each unique value, get the count / len of data (aka percentage)\n",
    "# num_clusters = labelled_data['cluster'].nunique()\n",
    "percentages = labelled_data['cluster'].value_counts().values\n",
    "percentages = percentages / labelled_data.shape[0]\n",
    "\n",
    "# keep cluster values with % < 5\n",
    "idx = (np.where(percentages <= 0.1)[0]).tolist()\n",
    "anomalies = labelled_data.loc[labelled_data['cluster'].isin(idx)]\n",
    "# output IPs within those selected clusters\n",
    "#print(f\"There are {len(an)}\")\n",
    "for i in anomalies['source_ip']:\n",
    "    print(f\"\\nIP {i} is a potential anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66c348f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value located at (array([278]), array([0]))\n",
      "278\n",
      "Using algorithm K-Means and feature configuration 278, max value is: 100.0\n"
     ]
    }
   ],
   "source": [
    "normed_Q = Q/ql.max(Q)*100\n",
    "max_location = np.where(normed_Q==normed_Q.max())\n",
    "print(\"max value located at\",max_location)\n",
    "max_config = max_location[0][0]\n",
    "max_algorithm = ALGORITHMS[max_location[1][0]]\n",
    "print(f\"Using algorithm {max_algorithm} and feature configuration {max_config}, max value is:\",normed_Q[278,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa379bf0",
   "metadata": {},
   "source": [
    "## Additional Reference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b7bb23-50fc-4abd-8090-852424c7c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q  :\n",
      "[[  0.      0.      0.      0.    258.44    0.   ]\n",
      " [  0.      0.      0.    321.8     0.    207.752]\n",
      " [  0.      0.    500.    321.8     0.      0.   ]\n",
      " [  0.    258.44  401.      0.    258.44    0.   ]\n",
      " [207.752   0.      0.    321.8     0.      0.   ]\n",
      " [  0.    258.44    0.      0.      0.      0.   ]]\n",
      "Normed Q :\n",
      "[[  0.       0.       0.       0.      51.688    0.    ]\n",
      " [  0.       0.       0.      64.36     0.      41.5504]\n",
      " [  0.       0.     100.      64.36     0.       0.    ]\n",
      " [  0.      51.688   80.2      0.      51.688    0.    ]\n",
      " [ 41.5504   0.       0.      64.36     0.       0.    ]\n",
      " [  0.      51.688    0.       0.       0.       0.    ]]\n",
      "Concept Path\n",
      "-> A\n",
      "-> E\n",
      "-> D\n",
      "-> C\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Markov Decision Process (MDP) - The Bellman equations adapted to\n",
    "# Q Learning.Reinforcement Learning with the Q action-value(reward) function.\n",
    "# Copyright 2019 Denis Rothman MIT License. See LICENSE.\n",
    "import numpy as ql\n",
    "# R is The Reward Matrix for each state\n",
    "R = ql.matrix([ [0,0,0,0,1,0],\n",
    "\t\t            [0,0,0,1,0,1],\n",
    "\t\t            [0,0,100,1,0,0],\n",
    "\t             \t[0,1,1,0,1,0],\n",
    "\t\t            [1,0,0,1,0,0],\n",
    "\t\t            [0,1,0,0,0,0] ])\n",
    "\n",
    "# Q is the Learning Matrix in which rewards will be learned/stored\n",
    "Q = ql.matrix(ql.zeros([6,6]))\n",
    "\n",
    "\"\"\"##  The Learning rate or training penalty\"\"\"\n",
    "\n",
    "# Gamma : It's a form of penalty or uncertainty for learning\n",
    "# If the value is 1 , the rewards would be too high.\n",
    "# This way the system knows it is learning.\n",
    "gamma = 0.8\n",
    "\n",
    "\"\"\"## Initial State\"\"\"\n",
    "\n",
    "# agent_s_state. The agent the name of the system calculating\n",
    "# s is the state the agent is going from and s' the state it's going to\n",
    "# this state can be random or it can be chosen as long as the rest of the choices\n",
    "# are not determined. Randomness is part of this stochastic process\n",
    "agent_s_state = 5\n",
    "\n",
    "\"\"\"## The random choice of the next state\"\"\"\n",
    "\n",
    "# The possible \"a\" actions when the agent is in a given state\n",
    "def possible_actions(state):\n",
    "    current_state_row = R[state,]\n",
    "    possible_act = ql.where(current_state_row >0)[1]\n",
    "    return possible_act\n",
    "\n",
    "# Get available actions in the current state\n",
    "PossibleAction = possible_actions(agent_s_state)\n",
    "\n",
    "# This function chooses at random which action to be performed within the range \n",
    "# of all the available actions.\n",
    "def ActionChoice(available_actions_range):\n",
    "    if(sum(PossibleAction)>0):\n",
    "        next_action = int(ql.random.choice(PossibleAction,1))\n",
    "    if(sum(PossibleAction)<=0):\n",
    "        next_action = int(ql.random.choice(5,1))\n",
    "    return next_action\n",
    "\n",
    "# Sample next action to be performed\n",
    "action = ActionChoice(PossibleAction)\n",
    "\n",
    "\"\"\"## The Bellman Equation\"\"\"\n",
    "\n",
    "# A version of the Bellman equation for reinforcement learning using the Q function\n",
    "# This reinforcement algorithm is a memoryless process\n",
    "# The transition function T from one state to another\n",
    "# is not in the equation below.  T is done by the random choice above\n",
    "\n",
    "def reward(current_state, action, gamma):\n",
    "    Max_State = ql.where(Q[action,] == ql.max(Q[action,]))[1]\n",
    "\n",
    "    if Max_State.shape[0] > 1:\n",
    "        Max_State = int(ql.random.choice(Max_State, size = 1))\n",
    "    else:\n",
    "        Max_State = int(Max_State)\n",
    "    MaxValue = Q[action, Max_State]\n",
    "    \n",
    "    # The Bellman MDP based Q function\n",
    "    Q[current_state, action] = R[current_state, action] + gamma * MaxValue\n",
    "\n",
    "# Rewarding Q matrix\n",
    "reward(agent_s_state,action,gamma)\n",
    "\n",
    "\"\"\"## Running the training episodes randomly\"\"\"\n",
    "\n",
    "# Learning over n iterations depending on the convergence of the system\n",
    "# A convergence function can replace the systematic repeating of the process\n",
    "# by comparing the sum of the Q matrix to that of Q matrix n-1 in the\n",
    "# previous episode\n",
    "for i in range(50000):\n",
    "    current_state = ql.random.randint(0, int(Q.shape[0]))\n",
    "    PossibleAction = possible_actions(current_state)\n",
    "    action = ActionChoice(PossibleAction)\n",
    "    reward(current_state,action,gamma)\n",
    "    \n",
    "# Displaying Q before the norm of Q phase\n",
    "print(\"Q  :\")\n",
    "print(Q)\n",
    "\n",
    "# Norm of Q\n",
    "print(\"Normed Q :\")\n",
    "print(Q/ql.max(Q)*100)\n",
    "\n",
    "\"\"\"# Improving the program by introducing a decision-making process\"\"\"\n",
    "nextc=-1\n",
    "nextci=-1\n",
    "conceptcode=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "origin=int(input(\"index number origin(A=0,B=1,C=2,D=3,E=4,F=5): \"))\n",
    "print(\"Concept Path\")\n",
    "print(\"->\",conceptcode[int(origin)])\n",
    "for se in range(0,6):\n",
    "    if(se==0):\n",
    "        po=origin\n",
    "    if(se>0):\n",
    "        po=nextci\n",
    "        #print(\"se:\",se,\"po:\",po)\n",
    "    for ci in range(0,6):\n",
    "        maxc=Q[po,ci]\n",
    "        #print(maxc,nextc)\n",
    "        if(maxc>=nextc):\n",
    "            nextc=maxc\n",
    "            nextci=ci\n",
    "            #print(\"next c\",nextc)\n",
    "    if(nextci==po):\n",
    "        break;\n",
    "    #print(\"present origin\",po,\"next c\",nextci,\" \",nextc,\" \",conceptcode[int(nextci)])\n",
    "    print(\"->\",conceptcode[int(nextci)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
